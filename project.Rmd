---
title: "ML Project"
author: "Michael"
date: "11 June 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# classfication of manner
The goal of this project is to predict the manner by using data collected by exercise devices. Attributes will be used are the ones related to belt, forearm, arm, and dumbell of 6 participants in dataset.Predictions are 5 manners in training dataset. RamdomForest will be used in this task. Pertentially, other an assembled model can be used in this task with other algorithms (GBM, SVM, LDA).

### Load Library and Data
```{r echo = FALSE}
library(caret)
library(randomForest)
library(gbm)
train <- read.csv("./pml-training.csv")
test <- read.csv("./pml-testing.csv")
```

### Data Preparation and missing values
Only relavent attributes will be used for training the model. There's no missing value found in these 52 attributes. Therefore, I skip filling in missing values.
```{r}
training <- train[, c('roll_belt', 'pitch_belt', 'yaw_belt', 'total_accel_belt', 'gyros_belt_x', 'gyros_belt_y', 'gyros_belt_z'
                    , 'accel_belt_x', 'accel_belt_y', 'accel_belt_z', 'magnet_belt_x', 'magnet_belt_y', 'magnet_belt_z'
                    , 'roll_arm', 'pitch_arm', 'yaw_arm', 'total_accel_arm', 'gyros_arm_x', 'gyros_arm_y', 'gyros_arm_z'
                    , 'accel_arm_x', 'accel_arm_y', 'accel_arm_z', 'magnet_arm_x', 'magnet_arm_y', 'magnet_arm_z'
                    , 'roll_dumbbell', 'pitch_dumbbell', 'yaw_dumbbell', 'total_accel_dumbbell', 'gyros_dumbbell_x'
                    , 'gyros_dumbbell_y', 'gyros_dumbbell_z', 'accel_dumbbell_x', 'accel_dumbbell_y', 'accel_dumbbell_z'
                    , 'magnet_dumbbell_x', 'magnet_dumbbell_y', 'magnet_dumbbell_z', 'roll_forearm', 'pitch_forearm', 'yaw_forearm'
                    , 'total_accel_forearm', 'gyros_forearm_x', 'gyros_forearm_y', 'gyros_forearm_z', 'accel_forearm_x'
                    , 'accel_forearm_y', 'accel_forearm_z', 'magnet_forearm_x', 'magnet_forearm_y', 'magnet_forearm_z'
                    , 'classe')]
row_na <- nrow(train[!complete.cases(training),])
row_na
```


### Exploratory Analysis with one example
Here I am trying to see if there's any patterns in the dataset.
```{r}
plot1 <- ggplot(training, aes(total_accel_belt, total_accel_arm, colour = classe)) +
            geom_point(stat = 'identity')
plot2 <- ggplot(training, aes(total_accel_belt, total_accel_dumbbell, colour = classe)) +
            geom_point(stat = 'identity')
plot3 <- ggplot(training, aes(total_accel_belt, total_accel_forearm, colour = classe)) +
            geom_point(stat = 'identity')
plot4 <- ggplot(training, aes(total_accel_arm, total_accel_dumbbell, colour = classe)) +
            geom_point(stat = 'identity')
plot5 <- ggplot(training, aes(total_accel_arm, total_accel_forearm, colour = classe)) +
            geom_point(stat = 'identity')
plot6 <- ggplot(training, aes(total_accel_dumbbell, total_accel_forearm, colour = classe)) +
            geom_point(stat = 'identity')
plot3
```

### Correlation check
Removing correlated attributes by using findCorrelation function in caret package. Tree models are not affected significantly by using correlated attributes, but Regression model does. 
```{r}
descrCor <- cor(training[, -53])
#summary(descrCor[upper.tri(descrCor)])
highlyCorDescr <- findCorrelation(descrCor, cutoff = .80)
training <- training[, -highlyCorDescr]
```

### Create training and testing dataset 
10 folds cross validation is defined here, and will be used in train function as one parameter. 
```{r}
set.seed(123456)
inTrain <- createDataPartition(y = training$classe, p = 0.8, list = FALSE)
cvTrain <- training[inTrain, ]
cvTest <- training[-inTrain, ]

fitCtrl <- trainControl(method = "repeatedcv", number = 10, repeats = 10)
```

### modelling in RandomForest
As practice, I used other methods to build a model. I don't display them as they take a large space in the analysis. RandomForest performs well here.
```{r}
set.seed(321)
rfFit <- train(classe ~ ., data = cvTrain, method = 'rf', ntree = 20, preProcess = c('center', 'scale'), trControl = fitCtrl)
```

### Prediction is created by using the trained model.
```{r}
rfPred <- predict(rfFit, cvTest)
```

### Validation on testing dataset.
```{r}
confusionMatrix(rfPred, cvTest$classe)
```

### Prediction on Test
```{r}
testPrediction <- predict(rfFit, newdata = test)
print(rbind(test[1:20, 160], as.character(testPrediction)))
```

### Summary
By using RandomForest with 20 trees in each cross validation (10 in total), the accuracy on testing data set is 0.9893. The final out of sample prediction is above.